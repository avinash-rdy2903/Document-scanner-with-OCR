{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_gen = ImageDataGenerator(rescale=1./255,shear_range=0.2,zoom_range=0.2)\n",
    "test_gen = ImageDataGenerator(rescale = 1./255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Found 97849 images belonging to 26 classes.\n",
      "Found 27300 images belonging to 26 classes.\n"
     ]
    }
   ],
   "source": [
    "train_set = train_gen.flow_from_directory(r'C:\\Users\\Avinash\\Desktop\\New folder\\OCR\\dataset\\ensembled\\train\\lowercase',target_size=(128,128),color_mode='rgb',batch_size=32,class_mode='categorical')\n",
    "test_set = test_gen.flow_from_directory(r'C:\\Users\\Avinash\\Desktop\\New folder\\OCR\\dataset\\ensembled\\test\\lowercase',class_mode='categorical',batch_size=16,target_size=(128,128),color_mode='rgb')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import InceptionV3\n",
    "inceptionV3 = InceptionV3(input_shape = (128,128,3), weights = 'imagenet',include_top=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "for layers in inceptionV3.layers:\n",
    "    layers.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= keras.layers.Flatten()(inceptionV3.output)\n",
    "inter = keras.layers.Dense(4096,activation='relu')(x)\n",
    "d1 = keras.layers.Dropout(0.3)(inter)\n",
    "inter_2 = keras.layers.Dense(2048,activation='relu')(d1)\n",
    "d2 = keras.layers.Dropout(0.2)(inter_2)\n",
    "out = keras.layers.Dense(26,activation='softmax')(d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_net = keras.Model(inputs = inceptionV3.input,outputs=out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_net.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['categorical_accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_net.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep_net.fit(train_set,epochs=64,steps_per_epoch=len(train_set),validation_data=test_set,validation_steps=test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "incep1 = keras.models.load_model('incep 85.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "4069/4069 [==============================] - 711s 173ms/step - loss: 0.8714 - accuracy: 0.7217\n"
     ]
    }
   ],
   "source": [
    "loss,acc=incep1.evaluate(test_set)"
   ]
  }
 ]
}