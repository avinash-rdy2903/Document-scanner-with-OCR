{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.4"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python394jvsc74a57bd063fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d",
   "display_name": "Python 3.9.4 64-bit"
  },
  "metadata": {
   "interpreter": {
    "hash": "63fd5069d213b44bf678585dea6b12cceca9941eaf7f819626cde1f2670de90d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "import cv2\n",
    "import random\n",
    "import pickle\n",
    "import sklearn\n",
    "import tensorflow as tf\n",
    "import progressbar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from image_preprocessing.scan import *\n",
    "from image_preprocessing.helper import resize,get_sorted_contours_bounding_box,skew_correction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "couldn't find the edges of the current doucment.\n",
      "At present, to improve accuracy we are working on skew correctrion on the present document\n",
      "Best angle: 0\n"
     ]
    }
   ],
   "source": [
    "img = cv2.imread(r'C:\\Users\\Avinash\\Desktop\\New folder\\OCR\\skew corrected.png')\n",
    "try:\n",
    "    img = document_warper(img)\n",
    "except FourPointException:\n",
    "    print(\"couldn't find the edges of the current doucment.\\nAt present, to improve accuracy we are working on skew correctrion on the present document\")\n",
    "    img = skew_correction(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(756, 1538, 3)\n"
     ]
    }
   ],
   "source": [
    "print(img.shape)\n",
    "gray = cv2.cvtColor(img,cv2.COLOR_RGB2GRAY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "edged = edge_detection(img)\n",
    "cnts,heirarchy = cv2.findContours(edged.copy(),cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "cnts,bounding_box = get_sorted_contours_bounding_box(cnts)\n",
    "cv2.imshow('w',gray)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars=[]\n",
    "boxs=[]\n",
    "for i,c in enumerate(cnts):\n",
    "    x,y,w,h = bounding_box[i]\n",
    "    if (w>=7 and w<=150) and (h>=15 and h<=150):\n",
    "        roi = gray[y:y+h,x:x+w]\n",
    "        thresh = cv2.threshold(roi,0,255,cv2.THRESH_BINARY | cv2.THRESH_OTSU)[1]\n",
    "        dims = random.randint(45,55)\n",
    "        thresh = cv2.resize(thresh,(dims,dims),cv2.INTER_CUBIC)\n",
    "        tH,tW = thresh.shape\n",
    "        dX = int(max(0,128-tW)/2.0)\n",
    "        dY = int(max(0,128-tH)/2.0)\n",
    "        padded = cv2.copyMakeBorder(thresh,top=dY,bottom=dY,right=dX,left=dX,borderType=cv2.BORDER_CONSTANT,value=(255,255,255))\n",
    "        padded = cv2.resize(padded,(128,128),cv2.INTER_CUBIC)\n",
    "        padded = padded.astype('float32')/255.\n",
    "        padded = np.expand_dims(padded,axis=-1)\n",
    "        boxs.append((x,y,w,h))\n",
    "        chars.append(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with tf.device('/cpu:0'):\n",
    "    nums = load_model('models/alex_net nums.h5')\n",
    "    lowercase = load_model('models/incep lower.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "with tf.device('/gpu:1'):\n",
    "    uppercase = load_model('models/incep upper.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open('final rf 0.90.sav','rb') as f:\n",
    "    random_forest = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "chars = np.array(chars,dtype='float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('classes/lower_classes.json','r') as f:\n",
    "    lower_classes = json.load(f)\n",
    "f.close()\n",
    "with open('classes/upper_classes.json','r') as f:\n",
    "    upper_classes = json.load(f)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "48"
      ]
     },
     "metadata": {},
     "execution_count": 14
    }
   ],
   "source": [
    "int('30',16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rf_classify(rf_preds,uc,lc,nums,chars,bar):\n",
    "    letter_class = []\n",
    "    probs = []\n",
    "    for i,c in enumerate(chars):\n",
    "        tmp = np.reshape(c,((1,)+c.shape))\n",
    "\n",
    "        if(rf_preds[i]==0):\n",
    "            \n",
    "            upper_pred = uppercase.predict(tmp)\n",
    "            lower_pred = lowercase.predict(tmp)\n",
    "            idx1,idx2 = np.argmax(upper_pred),np.argmax(lower_pred)\n",
    "            final_class = chr(int(upper_classes[str(idx1)],16))\n",
    "            prob = upper_pred[0][idx1]\n",
    "            if(upper_pred[0][idx1]<lower_pred[0][idx2]):\n",
    "                final_class = chr(int(lower_classes[str(idx2)],16))\n",
    "                prob = lower_pred[0][idx2]\n",
    "        if(rf_preds[i]==1 or prob<0.5):\n",
    "\n",
    "            preds = nums.predict(tmp)\n",
    "            idx1 = np.argmax(preds)\n",
    "            final_class = chr(48+idx1)\n",
    "            prob = preds[0][idx1]\n",
    "        letter_class.append(final_class)\n",
    "        probs.append(prob)\n",
    "        bar.update(i)\n",
    "    return letter_class,probs\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[Parallel(n_jobs=8)]: Using backend ThreadingBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=8)]: Done  34 tasks      | elapsed:    0.0s\n",
      "[Parallel(n_jobs=8)]: Done 170 out of 170 | elapsed:    0.1s finished\n"
     ]
    }
   ],
   "source": [
    "\n",
    "rf_preds=random_forest.predict(chars.reshape((chars.shape[0],chars.shape[1]*chars.shape[2])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Classifying images [elapsed time: 0:02:45] |================| (Time:  0:02:45) \n",
      "Creating a overview images [elapsed time: 0:00:00] |========| (Time:  0:00:00) \n"
     ]
    }
   ],
   "source": [
    "\n",
    "  \n",
    "widgets = ['Classifying images [',\n",
    "         progressbar.Timer(format= 'elapsed time: %(elapsed)s'),\n",
    "         '] ',\n",
    "           progressbar.Bar('='),' (',\n",
    "           progressbar.ETA(), ') ',\n",
    "          ]  \n",
    "          \n",
    "\n",
    "progressbar.streams.flush()\n",
    "bar = progressbar.ProgressBar(max_value=chars.shape[0],\n",
    "                              widgets=widgets).start()\n",
    "\n",
    "\n",
    "labels,probs = rf_classify(rf_preds,uppercase,lowercase,nums,chars,bar)\n",
    "bar.finish()\n",
    "for (label,(x,y,w,h),prob) in zip(labels,boxs,probs):\n",
    "    \n",
    "    cv2.rectangle(img,(x,y),(x+w,y+h),(0,255,0),2)\n",
    "    cv2.putText(img,label,(x-10,y-10),cv2.FONT_HERSHEY_SIMPLEX,1.2,(0,255,0),2)\n",
    "    \n",
    "    \n",
    "cv2.imshow('final',img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ],
   "source": [
    "cv2.imwrite(r\"C:\\Users\\Avinash\\Desktop\\New folder\\OCR\\test result\\hello world.jpg\",img)"
   ]
  }
 ]
}